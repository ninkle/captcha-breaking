{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from skimage.measure import block_reduce\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, name, filter_height, filter_width, num_filters, strides=[1, 4, 4, 1], padding=\"SAME\", groups=1):\n",
    "    channels = int(x.shape[-1])\n",
    "    \n",
    "    # create lambda function for convolution\n",
    "    convolve = lambda a, b: tf.nn.conv2d(a, b, strides=strides, padding=padding)\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        w = tf.get_variable(\"w\", shape=[filter_height, filter_width, int(channels/groups), num_filters])\n",
    "        b = tf.get_variable(\"b\", shape=[num_filters])\n",
    "        \n",
    "        conv = convolve(x, w)    \n",
    "        output = tf.reshape(tf.nn.bias_add(conv, b), conv.shape.as_list())\n",
    "        relu = tf.nn.relu(output, name=scope.name)\n",
    "        \n",
    "        return relu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(x, dim_in, dim_out, name):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        w = tf.get_variable(\"w\", shape=[dim_in, dim_out], trainable=True)\n",
    "        b = tf.get_variable(\"b\", [dim_out], trainable=True)\n",
    "        \n",
    "        output = tf.matmul(x, w) + b\n",
    "        relu = tf.nn.relu(output) \n",
    "        \n",
    "        return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(x, filter_height, filter_width, stride_y, stride_x, name, padding='SAME'):\n",
    "  return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1], \n",
    "                        strides = [1, stride_y, stride_x, 1], padding=padding, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrn(x, name, radius=5, alpha=0.0001, beta=0.75, bias=2.0):\n",
    "  return tf.nn.local_response_normalization(x, depth_radius=radius, alpha=alpha, beta=beta, bias=bias, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, keep_prob):\n",
    "  return tf.nn.dropout(x, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_dim = (224, 224, 3)\n",
    "n_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=n_dim)  \n",
    "Y = tf.placeholder(tf.float32,[None,n_classes])\n",
    "\n",
    "## REST OF GRAPH HERE #\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing CAPTCHA images\n",
    "\n",
    "As with the ImageNet data, we need virtually no preprocessing, save for downsampling the images (currently `100x100`) to fit the dimensions of our input layer (`64x64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# iterate through recaptcha dataset\n",
    "for folder in os.listdir(\"recapt_offline\"):\n",
    "    if folder != \".DS_Store\":\n",
    "        for file in os.listdir(\"recapt_offline/\"+folder):\n",
    "            if file == \"info.txt\":\n",
    "                json_string = open(\"recapt_offline/\"+folder+\"/\"+file, \"r\")\n",
    "                json_dict = json.load(json_string)  # convert json to dict\n",
    "                \n",
    "                correct = json_dict[\"correct_answer\"]  # array of numbers containing indices (1-9) of correct images\n",
    "                target = json_dict[\"desc\"][\"keyword\"]  # string representing target image (e.g. \"cake\")\n",
    "                \n",
    "            if \"cand\" in file:\n",
    "                img = Image.open(\"recapt_offline/\"+folder+\"/\"+file, \"r\")\n",
    "                downsampled = block_reduce(np.array(img), block_size=(2, 2, 1), func=np.mean)\n",
    "                # print(downsampled)\n",
    "                new = Image.fromarray(downsampled, 'RGB')\n",
    "                # plt.figure()\n",
    "                # plt.imshow(downsampled, interpolation=\"None\")\n",
    "                # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
